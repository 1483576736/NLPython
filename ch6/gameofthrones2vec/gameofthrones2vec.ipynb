{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import codecs\n",
    "import glob\n",
    "import logging\n",
    "import multiprocessing\n",
    "import os\n",
    "import pprint\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "import gensim.models.word2vec as w2v\n",
    "import sklearn.manifold\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/jalaj/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /home/jalaj/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download(\"punkt\")\n",
    "nltk.download(\"stopwords\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "book_filenames = sorted(glob.glob(\"/home/jalaj/PycharmProjects/NLPython/NLPython/ch6/gameofthrones2vec/data/*.txt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found books:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['/home/jalaj/PycharmProjects/NLPython/NLPython/ch6/gameofthrones2vec/data/got1.txt',\n",
       " '/home/jalaj/PycharmProjects/NLPython/NLPython/ch6/gameofthrones2vec/data/got2.txt',\n",
       " '/home/jalaj/PycharmProjects/NLPython/NLPython/ch6/gameofthrones2vec/data/got3.txt',\n",
       " '/home/jalaj/PycharmProjects/NLPython/NLPython/ch6/gameofthrones2vec/data/got4.txt',\n",
       " '/home/jalaj/PycharmProjects/NLPython/NLPython/ch6/gameofthrones2vec/data/got5.txt']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Found books:\")\n",
    "book_filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading '/home/jalaj/PycharmProjects/NLPython/NLPython/ch6/gameofthrones2vec/data/got1.txt'...\n",
      "Corpus is now 1770659 characters long\n",
      "\n",
      "Reading '/home/jalaj/PycharmProjects/NLPython/NLPython/ch6/gameofthrones2vec/data/got2.txt'...\n",
      "Corpus is now 4071041 characters long\n",
      "\n",
      "Reading '/home/jalaj/PycharmProjects/NLPython/NLPython/ch6/gameofthrones2vec/data/got3.txt'...\n",
      "Corpus is now 6391405 characters long\n",
      "\n",
      "Reading '/home/jalaj/PycharmProjects/NLPython/NLPython/ch6/gameofthrones2vec/data/got4.txt'...\n",
      "Corpus is now 8107945 characters long\n",
      "\n",
      "Reading '/home/jalaj/PycharmProjects/NLPython/NLPython/ch6/gameofthrones2vec/data/got5.txt'...\n",
      "Corpus is now 9719485 characters long\n",
      "\n"
     ]
    }
   ],
   "source": [
    "corpus_raw = u\"\"\n",
    "for book_filename in book_filenames:\n",
    "    print(\"Reading '{0}'...\".format(book_filename))\n",
    "    with codecs.open(book_filename, \"r\", \"utf-8\") as book_file:\n",
    "        corpus_raw += book_file.read()\n",
    "    print(\"Corpus is now {0} characters long\".format(len(corpus_raw)))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "tokenizer = nltk.data.load('tokenizers/punkt/english.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "raw_sentences = tokenizer.tokenize(corpus_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#convert into a list of words\n",
    "#rtemove unnnecessary,, split into words, no hyphens\n",
    "#list of words\n",
    "def sentence_to_wordlist(raw):\n",
    "    clean = re.sub(\"[^a-zA-Z]\",\" \", raw)\n",
    "    words = clean.split()\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#sentence where each word is tokenized\n",
    "sentences = []\n",
    "for raw_sentence in raw_sentences:\n",
    "    if len(raw_sentence) > 0:\n",
    "        sentences.append(sentence_to_wordlist(raw_sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Heraldic crest by Virginia Norey.\n",
      "[u'Heraldic', u'crest', u'by', u'Virginia', u'Norey']\n"
     ]
    }
   ],
   "source": [
    "print(raw_sentences[5])\n",
    "print(sentence_to_wordlist(raw_sentences[5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The book corpus contains 1,818,103 tokens\n"
     ]
    }
   ],
   "source": [
    "token_count = sum([len(sentence) for sentence in sentences])\n",
    "print(\"The book corpus contains {0:,} tokens\".format(token_count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#ONCE we have vectors\n",
    "#step 3 - build model\n",
    "#3 main tasks that vectors help with\n",
    "#DISTANCE, SIMILARITY, RANKING\n",
    "\n",
    "# Dimensionality of the resulting word vectors.\n",
    "#more dimensions, more computationally expensive to train\n",
    "#but also more accurate\n",
    "#more dimensions = more generalized\n",
    "num_features = 300\n",
    "# Minimum word count threshold.\n",
    "min_word_count = 3\n",
    "\n",
    "# Number of threads to run in parallel.\n",
    "#more workers, faster we train\n",
    "num_workers = multiprocessing.cpu_count()\n",
    "\n",
    "# Context window length.\n",
    "context_size = 7\n",
    "\n",
    "# Downsample setting for frequent words.\n",
    "#0 - 1e-5 is good for this\n",
    "downsampling = 1e-3\n",
    "\n",
    "# Seed for the RNG, to make the results reproducible.\n",
    "#random number generator\n",
    "#deterministic, good for debugging\n",
    "seed = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "thrones2vec = w2v.Word2Vec(\n",
    "    sg=1,\n",
    "    seed=seed,\n",
    "    workers=num_workers,\n",
    "    size=num_features,\n",
    "    min_count=min_word_count,\n",
    "    window=context_size,\n",
    "    sample=downsampling\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-05-22 12:51:29,328 : INFO : collecting all words and their counts\n",
      "2017-05-22 12:51:29,330 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2017-05-22 12:51:29,376 : INFO : PROGRESS: at sentence #10000, processed 140984 words, keeping 10280 word types\n",
      "2017-05-22 12:51:29,452 : INFO : PROGRESS: at sentence #20000, processed 279730 words, keeping 13558 word types\n",
      "2017-05-22 12:51:29,494 : INFO : PROGRESS: at sentence #30000, processed 420336 words, keeping 16598 word types\n",
      "2017-05-22 12:51:29,540 : INFO : PROGRESS: at sentence #40000, processed 556581 words, keeping 18324 word types\n",
      "2017-05-22 12:51:29,591 : INFO : PROGRESS: at sentence #50000, processed 686247 words, keeping 19714 word types\n",
      "2017-05-22 12:51:29,642 : INFO : PROGRESS: at sentence #60000, processed 828497 words, keeping 21672 word types\n",
      "2017-05-22 12:51:29,694 : INFO : PROGRESS: at sentence #70000, processed 973830 words, keeping 23093 word types\n",
      "2017-05-22 12:51:29,752 : INFO : PROGRESS: at sentence #80000, processed 1114967 words, keeping 24252 word types\n",
      "2017-05-22 12:51:29,809 : INFO : PROGRESS: at sentence #90000, processed 1260481 words, keeping 26007 word types\n",
      "2017-05-22 12:51:29,858 : INFO : PROGRESS: at sentence #100000, processed 1393203 words, keeping 26884 word types\n",
      "2017-05-22 12:51:29,908 : INFO : PROGRESS: at sentence #110000, processed 1532150 words, keeping 27809 word types\n",
      "2017-05-22 12:51:29,958 : INFO : PROGRESS: at sentence #120000, processed 1680961 words, keeping 28486 word types\n",
      "2017-05-22 12:51:29,996 : INFO : collected 29026 word types from a corpus of 1818103 raw words and 128868 sentences\n",
      "2017-05-22 12:51:29,997 : INFO : Loading a fresh vocabulary\n",
      "2017-05-22 12:51:30,068 : INFO : min_count=3 retains 17277 unique words (59% of original 29026, drops 11749)\n",
      "2017-05-22 12:51:30,070 : INFO : min_count=3 leaves 1802699 word corpus (99% of original 1818103, drops 15404)\n",
      "2017-05-22 12:51:30,156 : INFO : deleting the raw counts dictionary of 29026 items\n",
      "2017-05-22 12:51:30,159 : INFO : sample=0.001 downsamples 50 most-common words\n",
      "2017-05-22 12:51:30,161 : INFO : downsampling leaves estimated 1404424 word corpus (77.9% of prior 1802699)\n",
      "2017-05-22 12:51:30,162 : INFO : estimated required memory for 17277 words and 300 dimensions: 50103300 bytes\n",
      "2017-05-22 12:51:30,241 : INFO : resetting layer weights\n"
     ]
    }
   ],
   "source": [
    "thrones2vec.build_vocab(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word2Vec vocabulary length: 17277\n"
     ]
    }
   ],
   "source": [
    "print(\"Word2Vec vocabulary length:\", len(thrones2vec.wv.vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-05-22 12:51:39,496 : INFO : training model with 4 workers on 17277 vocabulary and 300 features, using sg=1 hs=0 sample=0.001 negative=5 window=7\n",
      "2017-05-22 12:51:39,499 : INFO : expecting 128868 sentences, matching count from corpus used for vocabulary survey\n",
      "2017-05-22 12:51:40,780 : INFO : PROGRESS: at 1.85% examples, 111834 words/s, in_qsize 8, out_qsize 0\n",
      "2017-05-22 12:51:41,788 : INFO : PROGRESS: at 3.73% examples, 120112 words/s, in_qsize 8, out_qsize 0\n",
      "2017-05-22 12:51:42,812 : INFO : PROGRESS: at 5.53% examples, 120326 words/s, in_qsize 8, out_qsize 0\n",
      "2017-05-22 12:51:43,861 : INFO : PROGRESS: at 7.44% examples, 119793 words/s, in_qsize 8, out_qsize 0\n",
      "2017-05-22 12:51:44,899 : INFO : PROGRESS: at 9.10% examples, 118149 words/s, in_qsize 8, out_qsize 0\n",
      "2017-05-22 12:51:45,933 : INFO : PROGRESS: at 10.49% examples, 114781 words/s, in_qsize 8, out_qsize 0\n",
      "2017-05-22 12:51:47,059 : INFO : PROGRESS: at 11.89% examples, 110930 words/s, in_qsize 8, out_qsize 0\n",
      "2017-05-22 12:51:48,060 : INFO : PROGRESS: at 13.21% examples, 108796 words/s, in_qsize 8, out_qsize 0\n",
      "2017-05-22 12:51:49,127 : INFO : PROGRESS: at 14.19% examples, 103834 words/s, in_qsize 8, out_qsize 0\n",
      "2017-05-22 12:51:50,404 : INFO : PROGRESS: at 15.03% examples, 96571 words/s, in_qsize 8, out_qsize 0\n",
      "2017-05-22 12:51:51,556 : INFO : PROGRESS: at 15.94% examples, 92438 words/s, in_qsize 8, out_qsize 0\n",
      "2017-05-22 12:51:52,558 : INFO : PROGRESS: at 16.81% examples, 89446 words/s, in_qsize 8, out_qsize 0\n",
      "2017-05-22 12:51:53,583 : INFO : PROGRESS: at 17.69% examples, 87828 words/s, in_qsize 8, out_qsize 0\n",
      "2017-05-22 12:51:54,666 : INFO : PROGRESS: at 18.69% examples, 86670 words/s, in_qsize 7, out_qsize 0\n",
      "2017-05-22 12:51:55,786 : INFO : PROGRESS: at 19.91% examples, 86300 words/s, in_qsize 8, out_qsize 0\n",
      "2017-05-22 12:51:56,949 : INFO : PROGRESS: at 20.85% examples, 84504 words/s, in_qsize 8, out_qsize 0\n",
      "2017-05-22 12:51:58,157 : INFO : PROGRESS: at 21.84% examples, 82893 words/s, in_qsize 7, out_qsize 0\n",
      "2017-05-22 12:51:59,133 : INFO : PROGRESS: at 22.87% examples, 82178 words/s, in_qsize 7, out_qsize 0\n",
      "2017-05-22 12:52:00,136 : INFO : PROGRESS: at 23.95% examples, 81908 words/s, in_qsize 7, out_qsize 0\n",
      "2017-05-22 12:52:01,136 : INFO : PROGRESS: at 25.07% examples, 81705 words/s, in_qsize 8, out_qsize 0\n",
      "2017-05-22 12:52:02,206 : INFO : PROGRESS: at 26.00% examples, 80580 words/s, in_qsize 7, out_qsize 0\n",
      "2017-05-22 12:52:03,211 : INFO : PROGRESS: at 26.94% examples, 79770 words/s, in_qsize 8, out_qsize 0\n",
      "2017-05-22 12:52:04,406 : INFO : PROGRESS: at 28.15% examples, 79043 words/s, in_qsize 8, out_qsize 0\n",
      "2017-05-22 12:52:05,468 : INFO : PROGRESS: at 29.30% examples, 79065 words/s, in_qsize 8, out_qsize 0\n",
      "2017-05-22 12:52:06,484 : INFO : PROGRESS: at 30.59% examples, 79536 words/s, in_qsize 7, out_qsize 0\n",
      "2017-05-22 12:52:07,513 : INFO : PROGRESS: at 32.00% examples, 80211 words/s, in_qsize 8, out_qsize 0\n",
      "2017-05-22 12:52:08,532 : INFO : PROGRESS: at 33.31% examples, 80597 words/s, in_qsize 7, out_qsize 0\n",
      "2017-05-22 12:52:09,583 : INFO : PROGRESS: at 34.65% examples, 80828 words/s, in_qsize 8, out_qsize 0\n",
      "2017-05-22 12:52:10,678 : INFO : PROGRESS: at 36.03% examples, 80953 words/s, in_qsize 8, out_qsize 0\n",
      "2017-05-22 12:52:11,762 : INFO : PROGRESS: at 37.36% examples, 81096 words/s, in_qsize 8, out_qsize 0\n",
      "2017-05-22 12:52:12,775 : INFO : PROGRESS: at 38.58% examples, 81393 words/s, in_qsize 8, out_qsize 0\n",
      "2017-05-22 12:52:13,801 : INFO : PROGRESS: at 39.89% examples, 81873 words/s, in_qsize 8, out_qsize 0\n",
      "2017-05-22 12:52:14,859 : INFO : PROGRESS: at 41.39% examples, 82478 words/s, in_qsize 7, out_qsize 0\n",
      "2017-05-22 12:52:16,062 : INFO : PROGRESS: at 42.95% examples, 82717 words/s, in_qsize 8, out_qsize 0\n",
      "2017-05-22 12:52:17,070 : INFO : PROGRESS: at 44.28% examples, 82958 words/s, in_qsize 8, out_qsize 0\n",
      "2017-05-22 12:52:18,231 : INFO : PROGRESS: at 45.62% examples, 82865 words/s, in_qsize 8, out_qsize 0\n",
      "2017-05-22 12:52:19,330 : INFO : PROGRESS: at 47.05% examples, 82916 words/s, in_qsize 8, out_qsize 0\n",
      "2017-05-22 12:52:20,337 : INFO : PROGRESS: at 48.51% examples, 83142 words/s, in_qsize 8, out_qsize 0\n",
      "2017-05-22 12:52:21,537 : INFO : PROGRESS: at 49.52% examples, 82596 words/s, in_qsize 8, out_qsize 0\n",
      "2017-05-22 12:52:22,651 : INFO : PROGRESS: at 50.89% examples, 82793 words/s, in_qsize 8, out_qsize 0\n",
      "2017-05-22 12:52:23,702 : INFO : PROGRESS: at 52.09% examples, 82756 words/s, in_qsize 8, out_qsize 0\n",
      "2017-05-22 12:52:24,771 : INFO : PROGRESS: at 53.32% examples, 82850 words/s, in_qsize 8, out_qsize 0\n",
      "2017-05-22 12:52:25,791 : INFO : PROGRESS: at 54.52% examples, 82687 words/s, in_qsize 8, out_qsize 0\n",
      "2017-05-22 12:52:26,910 : INFO : PROGRESS: at 55.67% examples, 82361 words/s, in_qsize 8, out_qsize 0\n",
      "2017-05-22 12:52:28,010 : INFO : PROGRESS: at 57.00% examples, 82392 words/s, in_qsize 8, out_qsize 0\n",
      "2017-05-22 12:52:29,012 : INFO : PROGRESS: at 58.06% examples, 82272 words/s, in_qsize 8, out_qsize 0\n",
      "2017-05-22 12:52:30,068 : INFO : PROGRESS: at 59.07% examples, 82072 words/s, in_qsize 8, out_qsize 0\n",
      "2017-05-22 12:52:31,091 : INFO : PROGRESS: at 60.20% examples, 82082 words/s, in_qsize 8, out_qsize 0\n",
      "2017-05-22 12:52:32,462 : INFO : PROGRESS: at 61.49% examples, 81706 words/s, in_qsize 7, out_qsize 1\n",
      "2017-05-22 12:52:33,623 : INFO : PROGRESS: at 62.49% examples, 81237 words/s, in_qsize 7, out_qsize 0\n",
      "2017-05-22 12:52:34,659 : INFO : PROGRESS: at 63.28% examples, 80686 words/s, in_qsize 7, out_qsize 0\n",
      "2017-05-22 12:52:35,967 : INFO : PROGRESS: at 64.03% examples, 79771 words/s, in_qsize 8, out_qsize 0\n",
      "2017-05-22 12:52:37,046 : INFO : PROGRESS: at 65.16% examples, 79691 words/s, in_qsize 8, out_qsize 0\n",
      "2017-05-22 12:52:38,014 : INFO : PROGRESS: at 66.08% examples, 79361 words/s, in_qsize 8, out_qsize 0\n",
      "2017-05-22 12:52:39,067 : INFO : PROGRESS: at 66.91% examples, 78868 words/s, in_qsize 8, out_qsize 0\n",
      "2017-05-22 12:52:40,294 : INFO : PROGRESS: at 68.25% examples, 78673 words/s, in_qsize 8, out_qsize 0\n",
      "2017-05-22 12:52:41,389 : INFO : PROGRESS: at 69.17% examples, 78404 words/s, in_qsize 8, out_qsize 0\n",
      "2017-05-22 12:52:42,452 : INFO : PROGRESS: at 70.04% examples, 78065 words/s, in_qsize 8, out_qsize 0\n",
      "2017-05-22 12:52:43,485 : INFO : PROGRESS: at 70.99% examples, 77893 words/s, in_qsize 8, out_qsize 0\n",
      "2017-05-22 12:52:44,485 : INFO : PROGRESS: at 71.97% examples, 77771 words/s, in_qsize 8, out_qsize 0\n",
      "2017-05-22 12:52:45,565 : INFO : PROGRESS: at 72.73% examples, 77320 words/s, in_qsize 8, out_qsize 0\n",
      "2017-05-22 12:52:46,621 : INFO : PROGRESS: at 73.53% examples, 77015 words/s, in_qsize 7, out_qsize 0\n",
      "2017-05-22 12:52:47,751 : INFO : PROGRESS: at 74.63% examples, 76756 words/s, in_qsize 8, out_qsize 0\n",
      "2017-05-22 12:52:48,938 : INFO : PROGRESS: at 75.78% examples, 76552 words/s, in_qsize 8, out_qsize 0\n",
      "2017-05-22 12:52:50,115 : INFO : PROGRESS: at 76.77% examples, 76188 words/s, in_qsize 7, out_qsize 0\n",
      "2017-05-22 12:52:51,143 : INFO : PROGRESS: at 77.66% examples, 76015 words/s, in_qsize 8, out_qsize 0\n",
      "2017-05-22 12:52:52,189 : INFO : PROGRESS: at 78.25% examples, 75552 words/s, in_qsize 8, out_qsize 0\n",
      "2017-05-22 12:52:53,294 : INFO : PROGRESS: at 79.46% examples, 75693 words/s, in_qsize 7, out_qsize 0\n",
      "2017-05-22 12:52:54,419 : INFO : PROGRESS: at 80.92% examples, 75973 words/s, in_qsize 7, out_qsize 0\n",
      "2017-05-22 12:52:55,507 : INFO : PROGRESS: at 82.36% examples, 76207 words/s, in_qsize 8, out_qsize 0\n",
      "2017-05-22 12:52:56,618 : INFO : PROGRESS: at 83.62% examples, 76207 words/s, in_qsize 8, out_qsize 0\n",
      "2017-05-22 12:52:57,755 : INFO : PROGRESS: at 84.60% examples, 75991 words/s, in_qsize 8, out_qsize 0\n",
      "2017-05-22 12:52:58,860 : INFO : PROGRESS: at 85.86% examples, 76008 words/s, in_qsize 8, out_qsize 0\n",
      "2017-05-22 12:52:59,871 : INFO : PROGRESS: at 87.03% examples, 76016 words/s, in_qsize 8, out_qsize 0\n",
      "2017-05-22 12:53:00,980 : INFO : PROGRESS: at 88.37% examples, 76024 words/s, in_qsize 8, out_qsize 0\n",
      "2017-05-22 12:53:02,021 : INFO : PROGRESS: at 89.71% examples, 76283 words/s, in_qsize 8, out_qsize 0\n",
      "2017-05-22 12:53:03,040 : INFO : PROGRESS: at 91.21% examples, 76649 words/s, in_qsize 8, out_qsize 0\n",
      "2017-05-22 12:53:04,264 : INFO : PROGRESS: at 92.51% examples, 76641 words/s, in_qsize 8, out_qsize 0\n",
      "2017-05-22 12:53:05,319 : INFO : PROGRESS: at 93.53% examples, 76595 words/s, in_qsize 8, out_qsize 0\n",
      "2017-05-22 12:53:06,323 : INFO : PROGRESS: at 94.75% examples, 76598 words/s, in_qsize 8, out_qsize 0\n",
      "2017-05-22 12:53:07,466 : INFO : PROGRESS: at 96.00% examples, 76564 words/s, in_qsize 8, out_qsize 0\n",
      "2017-05-22 12:53:08,492 : INFO : PROGRESS: at 97.12% examples, 76548 words/s, in_qsize 7, out_qsize 0\n",
      "2017-05-22 12:53:09,691 : INFO : PROGRESS: at 97.86% examples, 76126 words/s, in_qsize 7, out_qsize 0\n",
      "2017-05-22 12:53:10,951 : INFO : PROGRESS: at 98.66% examples, 75747 words/s, in_qsize 8, out_qsize 0\n",
      "2017-05-22 12:53:12,177 : INFO : PROGRESS: at 99.46% examples, 75408 words/s, in_qsize 6, out_qsize 0\n",
      "2017-05-22 12:53:12,573 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2017-05-22 12:53:12,610 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2017-05-22 12:53:12,696 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2017-05-22 12:53:12,802 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2017-05-22 12:53:12,805 : INFO : training on 9090515 raw words (7022378 effective words) took 93.2s, 75347 effective words/s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "7022378"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "thrones2vec.train(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "if not os.path.exists(\"trained\"):\n",
    "    os.makedirs(\"trained\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-05-22 12:53:18,291 : INFO : saving Word2Vec object under trained/thrones2vec.w2v, separately None\n",
      "2017-05-22 12:53:18,293 : INFO : not storing attribute syn0norm\n",
      "2017-05-22 12:53:18,296 : INFO : not storing attribute cum_table\n",
      "2017-05-22 12:53:18,922 : INFO : saved trained/thrones2vec.w2v\n"
     ]
    }
   ],
   "source": [
    "thrones2vec.save(os.path.join(\"trained\", \"thrones2vec.w2v\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-05-22 12:53:22,785 : INFO : loading Word2Vec object from trained/thrones2vec.w2v\n",
      "2017-05-22 12:53:23,020 : INFO : loading wv recursively from trained/thrones2vec.w2v.wv.* with mmap=None\n",
      "2017-05-22 12:53:23,021 : INFO : setting ignored attribute syn0norm to None\n",
      "2017-05-22 12:53:23,022 : INFO : setting ignored attribute cum_table to None\n",
      "2017-05-22 12:53:23,023 : INFO : loaded trained/thrones2vec.w2v\n"
     ]
    }
   ],
   "source": [
    "thrones2vec = w2v.Word2Vec.load(os.path.join(\"trained\", \"thrones2vec.w2v\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "tsne = sklearn.manifold.TSNE(n_components=2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "all_word_vectors_matrix = thrones2vec.wv.syn0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "all_word_vectors_matrix_2d = tsne.fit_transform(all_word_vectors_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "points = pd.DataFrame(\n",
    "    [\n",
    "        (word, coords[0], coords[1])\n",
    "        for word, coords in [\n",
    "            (word, all_word_vectors_matrix_2d[thrones2vec.vocab[word].index])\n",
    "            for word in thrones2vec.vocab\n",
    "        ]\n",
    "    ],\n",
    "    columns=[\"word\", \"x\", \"y\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "points.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sns.set_context(\"poster\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "points.plot.scatter(\"x\", \"y\", s=10, figsize=(20, 12))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_region(x_bounds, y_bounds):\n",
    "    slice = points[\n",
    "        (x_bounds[0] <= points.x) &\n",
    "        (points.x <= x_bounds[1]) & \n",
    "        (y_bounds[0] <= points.y) &\n",
    "        (points.y <= y_bounds[1])\n",
    "    ]\n",
    "    \n",
    "    ax = slice.plot.scatter(\"x\", \"y\", s=35, figsize=(10, 8))\n",
    "    for i, point in slice.iterrows():\n",
    "        ax.text(point.x + 0.005, point.y + 0.005, point.word, fontsize=11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plot_region(x_bounds=(4.0, 4.2), y_bounds=(-0.5, -0.1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plot_region(x_bounds=(0, 1), y_bounds=(4, 4.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-05-22 12:53:41,884 : INFO : precomputing L2-norms of word weight vectors\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(u'Eddard', 0.7480276226997375),\n",
       " (u'Winterfell', 0.6750659346580505),\n",
       " (u'direwolf', 0.6425904035568237),\n",
       " (u'Hornwood', 0.6366876363754272),\n",
       " (u'Lyanna', 0.6365906000137329),\n",
       " (u'beheaded', 0.6254189014434814),\n",
       " (u'Karstark', 0.6238248348236084),\n",
       " (u'executed', 0.6236813068389893),\n",
       " (u'Brandon', 0.6221044659614563),\n",
       " (u'Robb', 0.620850682258606)]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "thrones2vec.wv.most_similar(\"Stark\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'Jaehaerys', 0.7663156390190125),\n",
       " (u'Mad', 0.7609344124794006),\n",
       " (u'Daeron', 0.7542939782142639),\n",
       " (u'reign', 0.7378734350204468),\n",
       " (u'Cruel', 0.7255479097366333),\n",
       " (u'Unworthy', 0.722900927066803),\n",
       " (u'Conquest', 0.7144717574119568),\n",
       " (u'Since', 0.7070102691650391),\n",
       " (u'Rhaegar', 0.706188976764679),\n",
       " (u'II', 0.7050039172172546)]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "thrones2vec.most_similar(\"Aerys\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'wolf', 0.6853885054588318),\n",
       " (u'SHAGGYDOG', 0.6638862490653992),\n",
       " (u'Rickon', 0.651175856590271),\n",
       " (u'Stark', 0.6425904035568237),\n",
       " (u'Ghost', 0.6304522752761841),\n",
       " (u'pup', 0.6185530424118042),\n",
       " (u'Robb', 0.6010775566101074),\n",
       " (u'GHOST', 0.5987852215766907),\n",
       " (u'eagle', 0.5979127883911133),\n",
       " (u'RICKON', 0.5888221263885498)]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "thrones2vec.most_similar(\"direwolf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def nearest_similarity_cosmul(start1, end1, end2):\n",
    "    similarities = thrones2vec.most_similar_cosmul(\n",
    "        positive=[end2, start1],\n",
    "        negative=[end1]\n",
    "    )\n",
    "    start2 = similarities[0][0]\n",
    "    print(\"{start1} is related to {end1}, as {start2} is related to {end2}\".format(**locals()))\n",
    "    return start2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stark is related to Winterfell, as Tully is related to Riverrun\n",
      "Jaime is related to sword, as drank is related to wine\n",
      "Arya is related to Nymeria, as Dany is related to dragons\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "u'Dany'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nearest_similarity_cosmul(\"Stark\", \"Winterfell\", \"Riverrun\")\n",
    "nearest_similarity_cosmul(\"Jaime\", \"sword\", \"wine\")\n",
    "nearest_similarity_cosmul(\"Arya\", \"Nymeria\", \"dragons\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
